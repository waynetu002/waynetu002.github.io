---

layout: post
title: agentic rag
category: 技术
tags: MachineLearning
keywords: llm agent

---

* TOC
{:toc}


## 简介（未完成）

与传统的线性RAG流程不同，Agentic 特性的产品是通过嵌入具有自主决策能力的专业化智能体，从根本上解决了传统方法的局限。这些智能体能够动态管理检索策略、迭代优化上下文理解、适应复杂工作流程，**将系统从被动信息处理转变为主动理解问题并规划解决**。将固定的工作流基于用户场景动态生成。

产品层面：问答（从L1到L4 复杂度也很大）、报告生成
技术层面：Agentic RAG 的基本概念及其核心 Agentic 模式，包括规划（planning）、工具使用（tool use）反思（reflection）以及多智能体协作（multi-agent collaboration）。PS： 有没有大一统工程框架在支持这些事儿？

|业务/技术|线性|workflow|单agent|multiagent|
|---|---|---|---|---|
|RAG/deepsearch|native rag|selfrag/corag/ircot等|search-r1等||
|deepresearch||planer/searcher/summarier等|依赖类似openai 为deepresearch 端到端训练的模型|supervior + xxsearcher|
|写作||outline_wirter/段落writer/润色||supervisor + xxwriter |
|openmanus（通用agent）||supervisor + planer + xxer + 执行环境||supervisor + planer + xxtool + 执行环境|
|画布||||supervisor + xxtool + 执行环境|

1. 从答疑到连接物理世界，业务发展的动力
    1. LLM 能力本身提升了
    2. 多工具协作（Tool Use）的成熟
    3. 长期记忆和自主性能力发展，记忆机制让 Agent 能记住用户习惯、历史任务，自动优化策略。自主性支持 Agent 根据反馈调整自身行为，不需要用户的每一步指令。
    4. 规划和推理模块的成熟：早期 LLM 只能“回答”，而现在已经可以“先思考计划”，再执行，更像人类的助理。
1. 一般情况下，需求能简单做就简单实现，避免用更复杂实现，比如rag 一般不用multiagent
2. multiagent 在agno 中用一个team 概念来承载，这样一般一个业务用team + agent + tool 三级概念来承接。尽力沉淀通用team + agent + tool 以及三者的协作链路，特殊业务场景就用特殊team + agent + tool 实现，作为子类存在。
2. 同一个技术架构在不同的业务领域也是侧重点不同，比如multiagent中的不同agent 在deepsearch/deepresearch 一般是分层/主从关系（按部就班干活儿），但在写作或者以创造力为主的场景，可能就更自由一些。

## 对比Naive RAG

Naive RAG方法在处理简单问题时表现良好，然而，当面对更复杂的问题时，Naive RAG的局限性就显现出来了。
1. 总结性问题：例如，“给我一个公司10K年度报告的总结”，Naive RAG难以在不丢失重要信息的情况下生成全面的总结。
2. 比较性问题：例如，“Milvus 2.4 与Milvus 2.3 区别有哪些”，Naive RAG难以有效地进行多文档比较。
3. 结构化分析和语义搜索：例如，“告诉我美国表现最好的网约车公司的风险因素”，Naive RAG难以在复杂的语义搜索和结构化分析中表现出色。
4. 一般性多部分问题：例如，“告诉我文章A中的支持X的论点，再告诉我文章B中支持Y的论点，按照我们的内部风格指南制作一个表格，然后基于这些事实生成你自己的结论”，Naive RAG难以处理多步骤、多部分的复杂任务。

Naive RAG上述痛点的原因
1. 单次处理：Naive RAG通常是一次性处理查询，缺乏多步骤的推理能力。
2. 缺乏查询理解和规划：Naive RAG无法深入理解查询的复杂性，也无法进行任务规划。
3. 缺乏工具使用能力：Naive RAG无法调用外部工具或API来辅助完成任务。
4. 缺乏反思和错误纠正：Naive RAG无法根据反馈进行自我改进。

[终于让Agentic RAG工作流正常运行了](https://mp.weixin.qq.com/s/dfHQ3Z6ym6pblVWTtuN7SA)Agentic RAG（代理型 RAG） 是**与 AI 智能体架构一起使用的 RAG**（检索增强生成）。
1. 首先，它需要具有一定的自主决策能力，如果你编写了一个执行一系列步骤的程序，其中一步是调用 LLM——恭喜你！你已经构建了一个调用 LLM 的程序工作流，只是不要称它为 AI 智能体。
2. AI 智能体还需要有某种与环境交互的方式。对于软件来说，这意味着进行 API 调用、检索数据、向 LLM 发送提示等。大多数 LLM 仅支持一种类型的工具：函数。

![](/public/upload/machine/agentic_chat_loop.jpg)

| 对比维度       | 传统RAG                     | Agentic RAG                     | 优势提升                         |
|----------------|----------------------------|--------------------------------|--------------------------------|
| 架构核心       | 检索-生成管道               | Agent框架+RAG工具              | 从流程到智能体的范式转变         |
| 决策机制       | 固定流程或简单规则          | 自主动态规划                   | 应对复杂任务的灵活性             |
| 检索策略       | 单一检索模式                | 多策略动态选择                 | 适配多样查询类型                 |
| 多源处理       | 通常单一数据源              | 多源协同检索                   | 综合异构信息能力                 |
| 工具集成       | 有限或需硬编码              | 动态工具调用                   | 扩展系统能力边界                 |
| 反思能力       | 通常不具备                  | 结果评估与过程优化             | 持续改进回答质量                 |
| 适用场景       | 简单事实性查询              | 复杂研究与分析任务             | 商业价值的显著提升               |

## 技术范式

一般过程：通过多个模型，或者本模型自己的回归方式来实现多步分解问题进而拆解，进而逐步解决。

笔者曾微调模型（要准备要给微调数据集），实践了一下ircot，通过与检索器进行多轮对话，系统地规划检索和细化查询，以获取有价值的知识，，这个过程一直持续到收集到足够的外部信息为止。但这一块其实很不可控，由于检索器和检索语料库的限制，在某些情况下可能无法获取回答问题的必要知识，导致**无限次迭代**。另一个是这个底层是依赖于大模型的判定能力，在每次迭代中，LLM根据当前状态进行推理，确定是否需要进一步的检索以及检索的具体信息。LLM生成查询并根据检索到的文档进行信息提取和答案推断。细分下来就是：
1. 检索规划能力，LLM需要明确识别解决查询所需的知识和进一步检索的具体信息。这意味着LLM在每次迭代开始时，都会评估当前已有知识的不足，并决定需要检索哪些新信息。
2. 信息提取能力，一旦LLM收到检索到的文档，它需要从中提取解决问题的关键信息。这一步骤类似于人类在阅读文档时的信息筛选过程，旨在去除无关信息，保留有用内容。
3. 答案推断能力，在收集到所有相关信息后，LLM使用推理来形成最终答案。这一步骤确保LLM能够基于现有信息生成准确且合理的答案，避免生成虚假信息。

### 路由 vs agent

1. 路由 + 多链路，路由是最简单的Agent推理形式，路由器识别出来问题属于哪种，然后使用对应的链路来解决。
    1. 训练专门的分类器 https://github.com/starsuzi/Adaptive-RAG/ EfficientRAG
    2. 对于复杂问题，复杂问题的处理链路仍需单独训练。
2. agentic chat，有一个很牛逼的 agent llm（难点也在这），未来新的链路是一个tool。实际上揉和了规划、调用、总结到一个llm。
    1. 从分层的角度将，最下层/基础的能力是一系列的tool，所以要有caller，上层是对问题的拆分（也就是规划）和汇总（summary）。
    2. 对于单步骤问题，tool的回答已经可以作为答案了，所以规划器除了输出final Answer也可以ignore_summary 来决定是否调用summary。
        ```
        {
            action: "ignore_summary"
            action_input: "tool1_name"  # 表示只用tool1的输出作为answer就行了，不必再summary了。
        } 
        ```
    3. [多智能体微调实践：α-UMi 开源](https://zhuanlan.zhihu.com/p/948582901)它要求LLM不仅要准确理解用户的查询意图，还要具备高超的任务规划能力、精准的工具选择与调用技巧，以及出色的总结归纳技能。其中，任务规划依赖于模型的逻辑推理能力；工具的选择与调用，则考验模型能否准确无误地编写请求；而工具调用结果的总结，则是对模型归纳总结技能的一次全面检验。传统的方法往往试图在单个开源LLM框架内整合所有这些复杂的能力，这一做法在面对容量更小的小型开源LLM时，其性能局限性尤为突出。更为严峻的是，现实世界中的工具更新迭代速度极快，这意味着一旦外部工具发生变化，整个LLM系统可能都需要重新训练和调整，这不仅耗费大量资源，也给模型的维护和升级带来了前所未有的挑战。因此，如何设计出既能保持灵活性和适应性，又能有效应对工具更新带来的挑战的LLM代理系统，成为了当前研究亟待解决的关键问题。为了应对上述的挑战，通义实验室提出了一种名为“α-UMi”的多LLM工具调用智能体框架。**“α-UMi”将单一LLM的能力分解为三个部分模型执行：规划器、调用器和总结器。每个部分由单个LLM执行，专注于特定的功能**。规划器依据系统当前状态生成策略，决定是否选择调用器或总结器生成后续输出。调用器根据策略调用具体工具，而总结器则在规划器的指导下，根据执行轨迹构建最终的用户答案。这些组件协同工作，共同完成任务。与先前的方法相比，α-UMi框架具有三大优势：
        1. 每个组件针对特定角色进行训练，确保了各自功能的优化。
        2. 其次，模块化设计允许各组件按需独立更新，保证了系统的适应性和维护效率。
        3. 由于每个组件聚焦于单一功能，缓解了模型等容量限制，意味着可以在小型LLM对工具调用智能体进行部署。
        PS:  好想法，就是工作量有点大，训练时为每个模型准备单独的样本？文中给出了代码框架和 基于一个base 模型微调后的规划器、调用器和总结器模型。caller 用一个function-call 来训练应该问题不大。
3. （引入强化学习）在deepsearch场景下，action 可以进一步明确为一个search动作（自然也会包含 query），所以涌现出一些Search-R1 等模型，由模型完全控制search loop。

### CoRAG

multistep 是单一的链式结构，链式结构中间的一个step的判断错误或者偏离了问题的本质，导致最终的输出会长且错（当然这里也会通过经过self-correct等训练方式来补救）

在 CoRAG 中
1. 候选链生成，CoRAG 会同时生成多个「查询-子答案链条」（检索链），每个链条是一个候选样本。
2. 计算接受概率（评估链条质量），根据当前链条的子答案质量、预测得分（模型给出的概率）等指标，模型可以评估某条链条是否可能通向正确答案。
3. 筛选有效链条（拒绝不好的链条），如果某条链的得分很低，或者生成的子答案不合理（比如与目标问题无关），模型会直接丢弃这条链，重新探索新的链条。
4. 选最优答案，通过拒绝那些“不可能得出正确答案”的链条，模型最终能保留较优解，避免浪费计算资源。
这个最好的链是怎么选的呢？需要你对模型LLM进行训练。优化学习更好生成子查询，更好生成子回答，更好生成最终答案。
PS：微调模型来提高拆解子问题的能力。 

### 计划和反思（未完成）

LLM 在具代理性的系统中如何决定使用哪个工具以及何时使用呢？这就是计划的作用。 LLM 代理中的计划涉及将给定任务分解为可操作的步骤。
1. no plan。llm 隐式的有一个计划，但不外漏。 
2. plan next/react
1. plan ahead/planning+execution。有时生成的计划赶不上变化和实际不符合，所以即便生成了计划，往往也会根据检索到的信息调整。

没有人，即使是具有 ReAct 的 LLM，也并非每个任务都能完美完成。失败是过程的一部分，只要你能反思这个过程就行。 

## 技术架构

[Agentic RAG: 构建自主决策型检索增强系统](https://mp.weixin.qq.com/s/vgWCIAO2hORCbqd5_BIwXQ) 与顺序式简单 RAG 架构相比，代理式 RAG 架构的核心是代理。Agentic RAG架构
1. 单代理 RAG（路由器），最简单的形式是，其核心思想是构建一个具备规划能力的 Master 智能体，将各种RAG管道和外部工具作为该 Agent 可调用的"工具"。在这种架构中，传统RAG的检索器、生成器等组件被工具化，成为 Agent 执行计划时可选择的资源。当用户查询进入系统后，Master Agent 会首先分析查询意图和复杂度，然后动态规划解决方案，可能包括：决定是否需要检索、选择哪种检索策略（如向量检索、关键词检索或混合检索）、确定是否需要进行多步检索以及是否需要调用外部工具等。
    1. 单代理RAG仅限于一个代理，集推理、检索和答案生成于一体。设计相对简单，适合中等复杂度的应用场景。
2. 多Agent分层架构（多agent 自由博弈在RAG场景下一般不太实用），通过引入层级化的 Agent 组织，实现关注点分离和专业化分工。典型的双层架构包含一个顶层协调Agent和多个专业领域Agent，每个下层Agent负责特定类型的数据源或任务，而顶层Agent则负责任务分解、协调和结果整合。
    1. 多Agent架构的核心优势在于其卓越的可扩展性和专业分工

实施 Agentic RAG，要构建代理 RAG 管道，有两种选择：具有函数调用的语言模型或代理框架。取决于您想要的控制和灵活性。
1. 具有函数调用的语言模型
2. 代理框架


## 对应用的影响

[AI 产品思维：我如何把一个 AI 应用从基础 RAG 升级到 multi-agent 架构](https://mp.weixin.qq.com/s/mVV558UD1KP4gn5nmyUnfg)从工作流的定义到边界与目标定义：软件产品专注于定义明确的用户旅程和工作流程。去梳理业务场景，然后把业务拆解为可解释的固定环节，然后对应构建产品，每个步骤都有确定的输入、输出和 UI 元素。产品经理精确规定系统在每个场景中的行为。AI 产品则需要根本不同的方法。产品经理不再规定精确工作流，而是定义：
1. 边界：智能体责任范围的清晰界限，
2. 目标：成功结果的明确标准，
3. 环境/容器：智能体有效运行所需的上下文环境

这种面向目标的方法关注智能体应当实现什么，而非在每种可能情况下如何实现，要更加的拥抱灰度，与此同时，要构建评估思维，因为需求的迭代不再是固定且线性的，这就需要有很强的评估思维（解决方案可能从"超出期望"到"基本满足需求"再到"没有解决问题"形成价值连续体），根据结果来反推 AI 系统中某个环节或某个变量的调整，形成反馈循环。


